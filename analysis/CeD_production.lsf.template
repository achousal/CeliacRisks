#!/bin/bash
#==============================================================
# CeD_production.lsf.template
#
# LSF batch script template for Celiac Disease ML pipeline
#
# SETUP INSTRUCTIONS:
# 1. Copy this file: cp CeD_production.lsf.template CeD_production.lsf
# 2. Edit CeD_production.lsf:
#    - Update #BSUB -P (project allocation)
#    - Update #BSUB -q (queue name)
#    - Update BASE_DIR path
#    - Customize resource requests if needed
# 3. Generate splits FIRST (required):
#    ced save-splits --config configs/splits_config.yaml \
#      --infile ../Celiac_dataset_proteomics.csv --n-splits 10
#    OR use ./run_production.sh to handle all steps
# 4. Submit: bsub < CeD_production.lsf
#
# Usage:
#   # Submit all 4 models
#   bsub < CeD_production.lsf
#
#   # Submit specific model
#   MODEL=LR_EN bsub -J "CeD_LR" < CeD_production.lsf
#
# Array job mapping (LSB_JOBINDEX 1-4):
#   1 → RF
#   2 → XGBoost
#   3 → LinSVM_cal
#   4 → LR_EN
#==============================================================

#BSUB -J "CeD_train[1-4]"
#BSUB -P YOUR_PROJECT_ALLOCATION     # REQUIRED: Update with your allocation
#BSUB -q normal                       # Queue name (normal, premium, etc.)
#BSUB -n 16                           # Number of CPU cores
#BSUB -W 12:00                        # Wall time (HH:MM)
#BSUB -R "span[hosts=1] rusage[mem=8000]"  # 8 GB per core = 128 GB total
#BSUB -oo logs/CeD_train_%J_%I.out
#BSUB -eo logs/CeD_train_%J_%I.err

set -euo pipefail

#==============================================================
# PATHS (Define early for venv activation)
#==============================================================
# REQUIRED: Update BASE_DIR to your project path
BASE_DIR="/path/to/your/CeliacRisks/analysis"  # UPDATE THIS

# Change to analysis directory and create output directories
cd "${BASE_DIR}" || exit 1
mkdir -p logs splits_production results_production

#==============================================================
# ENVIRONMENT
#==============================================================
# Load required modules (customize for your HPC)
if command -v module >/dev/null 2>&1; then
  module load python/3.9.0 2>/dev/null || true
fi

# Activate virtual environment (now that we're in BASE_DIR)
source venv/bin/activate

echo "[$(date +'%F %T')] Python: $(which python)"
echo "[$(date +'%F %T')] ced version: $(ced --version)"

# Define remaining paths
INFILE="${BASE_DIR}/../Celiac_dataset_proteomics.csv"
SPLITS_DIR="${BASE_DIR}/splits_production"
RESULTS_DIR="${BASE_DIR}/results_production"
LOGS_DIR="${BASE_DIR}/logs"
CONFIG_FILE="${BASE_DIR}/configs/training_config.yaml"

#==============================================================
# HPC RESOURCE MANAGEMENT
#==============================================================
CPUS="${LSB_DJOB_NUMPROC:-16}"

# Disable nested parallelism (critical for performance)
export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export NUMEXPR_NUM_THREADS=1
export BLIS_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export OMP_DYNAMIC=FALSE
export MKL_DYNAMIC=FALSE
export LOKY_MAX_CPU_COUNT="${CPUS}"

# Temp directory for joblib
export JOBLIB_TEMP_FOLDER="/tmp/${USER}/joblib_${LSB_JOBID}_${LSB_JOBINDEX}"
export TMPDIR="${JOBLIB_TEMP_FOLDER}"
mkdir -p "${JOBLIB_TEMP_FOLDER}"
cleanup() { rm -rf "${JOBLIB_TEMP_FOLDER}" 2>/dev/null || true; }
trap cleanup EXIT

#==============================================================
# MODEL SELECTION
#==============================================================
# Map job array index to model name
MODELS=(RF XGBoost LinSVM_cal LR_EN)

# Allow manual override via MODEL env var
if [[ -n "${MODEL:-}" ]]; then
  MODEL_NAME="${MODEL}"
else
  MODEL_IDX=$((LSB_JOBINDEX - 1))
  if [[ ${MODEL_IDX} -ge ${#MODELS[@]} ]]; then
    echo "ERROR: LSB_JOBINDEX=${LSB_JOBINDEX} out of range (max 4)"
    exit 1
  fi
  MODEL_NAME="${MODELS[$MODEL_IDX]}"
fi

echo "[$(date +'%F %T')] ============================================"
echo "[$(date +'%F %T')] Job Configuration:"
echo "[$(date +'%F %T')]   LSF Job ID: ${LSB_JOBID}"
echo "[$(date +'%F %T')]   Array Index: ${LSB_JOBINDEX}"
echo "[$(date +'%F %T')]   Model: ${MODEL_NAME}"
echo "[$(date +'%F %T')]   CPUs: ${CPUS}"
echo "[$(date +'%F %T')]   Config: ${CONFIG_FILE}"
echo "[$(date +'%F %T')] ============================================"

#==============================================================
# TRAINING
#==============================================================
# Run training using ced CLI
ced train \
  --config "${CONFIG_FILE}" \
  --model "${MODEL_NAME}" \
  --infile "${INFILE}" \
  --split-dir "${SPLITS_DIR}" \
  --outdir "${RESULTS_DIR}"

#==============================================================
# VALIDATION
#==============================================================
OUTPUT_PATTERN="${RESULTS_DIR}/IncidentPlusPrevalent__${MODEL_NAME}__*/core/test_metrics.csv"

if compgen -G "${OUTPUT_PATTERN}" > /dev/null 2>&1; then
  echo "[$(date +'%F %T')] ✓ Training completed successfully for ${MODEL_NAME}"
  echo "[$(date +'%F %T')] Output: $(echo ${OUTPUT_PATTERN})"
else
  echo "[$(date +'%F %T')] ✗ Training failed for ${MODEL_NAME}"
  echo "[$(date +'%F %T')] Expected output not found: ${OUTPUT_PATTERN}"
  exit 1
fi

echo "[$(date +'%F %T')] ============================================"
echo "[$(date +'%F %T')] Job completed successfully"
echo "[$(date +'%F %T')] ============================================"
