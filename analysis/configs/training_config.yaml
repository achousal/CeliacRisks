# Training Configuration
# Model training for Celiac Disease risk prediction

scenario: IncidentPlusPrevalent  # Options: IncidentOnly, PrevalentOnly, IncidentPlusPrevalent

# Cross-validation
cv:
  folds: 3
  repeats: 2
  scoring: roc_auc  # Options: roc_auc, average_precision, neg_brier_score
  # n_iter: 2  # Global override: if set, overrides ALL per-model n_iter values below
  inner_folds: 3
  n_jobs: 1  # CRITICAL: Set to 1 to prevent nested parallelism memory explosion (was -1)
  random_state: 42
  grid_randomize: true  # Randomize numeric grid values for more diverse search
  verbose: 1
  # Local testing: 3 folds x 2 repeats = 6 CV splits (lightweight)

# Ensemble training: Use separate CLI command `ced train-ensemble`
# See docs/reference/CLI_REFERENCE.md for usage

# Optuna hyperparameter optimization (optional alternative to RandomizedSearchCV)
optuna:
  enabled: true  # Set to true to use Optuna instead of RandomizedSearchCV
  n_trials: 40  # Number of hyperparameter trials (exploratory local testing)
  timeout: null  # Optional timeout in seconds (null = no limit)
  sampler: tpe  # Options: tpe, random, cmaes, grid
  sampler_seed: 42  # Seed for reproducibility
  pruner: hyperband  # Options: median, percentile, hyperband, none
  pruner_n_startup_trials: 5  # Number of trials before pruning starts
  pruner_percentile: 20.0  # Percentile for percentile pruner (0-100)
  n_jobs: 4  # CRITICAL: Limit parallelism to prevent memory explosion with CalibratedClassifierCV (was -1)
  save_study: true  # Save Optuna study object
  save_trials_csv: true  # Save trials as CSV

# Feature selection
# Switch strategy by changing feature_selection_strategy value
# All parameters for all strategies are defined below
features:
  # Strategy selection (change this to switch methods)
  feature_selection_strategy: hybrid_stability  # Options: hybrid_stability, rfecv, none
  # - hybrid_stability: Fast (~30 min), screen → k-best → stability → corr-prune
  # - rfecv: Rigorous (~4-5h with k-best=100), screen → RFE with CV
  # - none: No feature selection (use all screened features)

  # Common: Screening (used by all strategies)
  screen_method: mannwhitney  # "mannwhitney" or "f_classif"
  screen_top_n: 1000  # Stage 1: Mann-Whitney → keep top 1000

  # Strategy 1: Hybrid Stability parameters (used if strategy=hybrid_stability)
  k_grid: [100]  # K-best tuning grid
  stability_thresh: 0.70  # Stability selection threshold
  stable_corr_thresh: 0.85  # Remove features with r > 0.85

  # Strategy 2: RFECV parameters (used if strategy=rfecv)
  # Uncomment these if switching to rfecv strategy
  # rfe_kbest_prefilter: true  # Enable k-best pre-filter (5× speedup)
  # rfe_kbest_k: 400  # Reduces ~300 → ~100 proteins before RFECV
  # rfe_target_size: 50  # Minimum features (stops at 50//2 = 25)
  # rfe_step_strategy: 5  # Options: adaptive, linear, geometric
  # rfe_cv_folds: 3  # Inner CV folds for RFE
  # rfe_consensus_thresh: 0.80  # Consensus threshold across CV repeats

# Model-specific hyperparameter search spaces
# These define the ranges for RandomizedSearchCV or Optuna optimization
#
# IMPORTANT: Parameters like max_iter and solver are FIXED (not tuned).
# They are set as baseline model parameters used by BOTH RandomizedSearchCV and Optuna.
# Only parameters with grids/ranges (C, l1_ratio, class_weight) are tuned.

# Logistic Regression (LR_EN, LR_L1)
lr:
  # Tuned parameters (explored by RandomizedSearchCV/Optuna):
  C_min: 0.0001            # Expanded range for exploration
  C_max: 10.0              # (was 1.0)
  C_points: 20             # (was 10)
  l1_ratio: [0.0, 0.05, 0.1, 0.15, 0.2, 0.3, 0.5, 0.7, 0.9, 1.0] # Expanded to include L1-heavy
  class_weight_options: "balanced"  # Options: "None", "balanced", "{0:1,1:5}"

  # Optuna-specific ranges (optional, override C_min/C_max):
  optuna_C: [1.0e-5, 100.0]         # Expanded for exploratory search
  optuna_l1_ratio: [0.0, 1.0]        # Full range

  # Fixed parameters (used as baseline for all trials):
  solver: saga              # Solver supporting L1/ElasticNet
  max_iter: 10000           # Increased for convergence (was 5000)

  # Search algorithm settings:
  n_iter: 4                 # RandomizedSearchCV iterations (ignored if optuna.enabled=true)

# Linear SVM (LinSVM_cal) - wrapped in CalibratedClassifierCV
svm:
  # Tuned parameters (explored by RandomizedSearchCV/Optuna):
  C_min: 0.0001             # Expanded range
  C_max: 10.0               # (was 1.0)
  C_points: 15              # (was 10)
  class_weight_options: "balanced"

  # Optuna-specific ranges (optional, override C_min/C_max):
  optuna_C: [1.0e-4, 100.0]         # Expanded for exploration

  # Fixed parameters (used as baseline for all trials):
  max_iter: 10000           # Increased for convergence (was 5000)

  # Search algorithm settings:
  n_iter: 6                 # RandomizedSearchCV iterations (ignored if optuna.enabled=true)

# Random Forest (RF)
rf:
  # Tuned parameters (explored by RandomizedSearchCV/Optuna):
  n_estimators_grid: [100, 300, 500, 700]    # Expanded (was [100, 300, 500])
  max_depth_grid: [null, 10, 20, 30, 50]     # Expanded (was [null, 10, 20, 30])
  min_samples_split_grid: [2, 5, 10, 20]     # Expanded (was [2, 5, 10])
  min_samples_leaf_grid: [1, 2, 4, 8]        # Expanded (was [1, 2, 4])
  max_features_grid: ["sqrt", "log2", 0.3, 0.5, 0.7]  # Expanded (was ["sqrt", "log2", 0.5])
  class_weight_options: "balanced"

  # Optuna-specific ranges (optional, override grid-derived ranges)
  optuna_n_estimators: [100, 800]            # Exploratory range
  optuna_max_depth: [5, 50]                  # Exploratory range
  optuna_min_samples_split: [2, 30]          # Exploratory range
  optuna_min_samples_leaf: [1, 15]           # Exploratory range
  optuna_max_features: [0.05, 0.8]           # Exploratory range

  # Search algorithm settings:
  n_iter: 2                 # RandomizedSearchCV iterations (ignored if optuna.enabled=true)

# XGBoost
xgboost:
  # Tuned parameters (explored by RandomizedSearchCV/Optuna):
  n_estimators_grid: [100, 200, 400, 800, 1200]        # Boosting rounds
  max_depth_grid: [3, 4, 5, 6, 7, 8]                   # Tree depth
  learning_rate_grid: [0.01, 0.03, 0.05, 0.1, 0.2]     # Exploratory learning rates
  subsample_grid: [0.5, 0.7, 0.85, 1.0]                # Expanded row subsampling
  colsample_bytree_grid: [0.3, 0.5, 0.7, 0.85, 1.0]    # Expanded column subsampling
  scale_pos_weight_grid: [3.0, 5.0, 6.0, 7.0, 10.0]    # Expanded class weight range
  min_child_weight_grid: [1, 2, 4, 6, 10]              # Min child weight
  gamma_grid: [0.0, 0.05, 0.1, 0.5, 1.0, 2.0]          # Expanded min split loss
  reg_alpha_grid: [0.0, 0.001, 0.01, 0.1, 1.0]         # L1 regularization
  reg_lambda_grid: [0.01, 0.1, 1.0, 5.0, 10.0, 50.0]   # Expanded L2 regularization

  # Optuna-specific ranges (optional, override grid-derived ranges)
  optuna_n_estimators: [50, 1500]            # Exploratory range
  optuna_max_depth: [3, 10]                  # Exploratory range
  optuna_learning_rate: [0.005, 0.3]         # Exploratory range
  optuna_min_child_weight: [0.1, 20.0]       # Exploratory range
  optuna_gamma: [0.0, 2.0]                   # Exploratory range
  optuna_subsample: [0.5, 1.0]               # Exploratory range
  optuna_colsample_bytree: [0.3, 1.0]        # Exploratory range
  optuna_reg_alpha: [1.0e-8, 10.0]           # Exploratory range (log-scale)
  optuna_reg_lambda: [1.0e-2, 50.0]          # Exploratory range (log-scale)

  # Fixed parameters (used as baseline for all trials):
  tree_method: hist                            # Algorithm: hist (fast), exact, approx

  # Search algorithm settings:
  n_iter: 2                 # RandomizedSearchCV iterations (ignored if optuna.enabled=true)

# Probability calibration
# Controls how model probabilities are calibrated for better reliability
calibration:
  enabled: true  # Whether to apply any calibration
  strategy: oof_posthoc  # Options: per_fold (default), oof_posthoc, none
  # - per_fold: Apply CalibratedClassifierCV inside each CV fold (current behavior, simple)
  # - oof_posthoc: Fit calibrator on pooled OOF predictions after CV (eliminates ~0.5-1% bias)
  # - none: No calibration applied
  method: isotonic  # Options: isotonic (nonparametric), sigmoid (Platt scaling)
  cv: 5  # CV folds for per_fold strategy
  # Per-model overrides (optional):
  # per_model:
  #   LR_EN: oof_posthoc  # Use oof_posthoc for logistic regression
  #   RF: per_fold        # Keep per_fold for random forest
  #   XGBoost: none       # No calibration for XGBoost

# Thresholding
thresholds:
  objective: fixed_spec  # "max_f1", "max_fbeta", "youden", "fixed_spec", "fixed_ppv"
  fixed_spec: 0.95  # Target 95% specificity
  fbeta: 1.0  # Beta parameter for max_fbeta objective
  fixed_ppv: 0.10  # Target PPV for fixed_ppv objective
  threshold_source: val  # Select threshold on VAL set
  target_prevalence_source: test  # Use TEST prevalence for calibration
  target_prevalence_fixed: null  # Override prevalence for calibration
  risk_prob_source: test  # Options: test, val

# Evaluation
evaluation:
  test_ci_bootstrap: true
  n_boot: 100  # Reduced for local testing (was 500, production: 1000)
  boot_random_state: 0
  learning_curve: true
  lc_train_sizes: [0.1, 0.25, 0.5, 0.75, 1.0]
  feature_reports: true
  feature_report_max: 200
  # Specificity targets for multi-target reporting
  control_spec_targets: [0.90, 0.95, 0.99]
  toprisk_fracs: [0.01, 0.05, 0.10]

# Decision curve analysis
dca:
  compute_dca: true
  dca_threshold_min: 0.0005
  dca_threshold_max: 1.0
  dca_threshold_step: 0.001
  dca_report_points: [0.01, 0.05, 0.10, 0.20]

# Outputs
output:
  save_train_preds: true
  save_train_oof: true
  save_val_preds: true
  save_test_preds: true
  save_calibration: true
  calib_bins: 6
  save_controls_oof: true
  save_feature_importance: true
  feature_reports: true
  plot_format: png  # Options: png, pdf, svg
  plot_dpi: 300
  save_plots: true

  # Individual plot type controls
  plot_roc: true
  plot_pr: true
  plot_calibration: true
  plot_risk_distribution: true
  plot_dca: true
  plot_learning_curve: true
  plot_oof_combined: true
  plot_optuna: true
