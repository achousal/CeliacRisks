â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          CELIAC RISK ML - CONFIGURATION KNOBS CHEATSHEET (v2026-01)        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ CRITICAL KNOBS (What? How many? How well?) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                            â”‚
â”‚ WHICH MODELS TO RUN?                                                      â”‚
â”‚   RUN_MODELS="RF,XGB,SVM,LR"   â†’ all 4 models in parallel (default)     â”‚
â”‚   RUN_MODELS="LR"               â†’ single model (debugging)               â”‚
â”‚   RUN_MODELS="RF,LR"            â†’ subset                                 â”‚
â”‚                                                                            â”‚
â”‚ HOW MANY DATA SPLITS?                                                    â”‚
â”‚   N_SPLITS=1                    â†’ single split (quick: ~2-4 hours)       â”‚
â”‚   N_SPLITS=10                   â†’ 10 repeated splits (robust: ~20-40h)   â”‚
â”‚   SEED_START=0 with N_SPLITS=10 â†’ seeds 0-9 (confidence intervals)       â”‚
â”‚                                                                            â”‚
â”‚ CROSS-VALIDATION SETUP (Outer CV for performance estimation)            â”‚
â”‚   FOLDS=5; REPEATS=10           â†’ 5Ã—10 = 50 OOF predictions/sample      â”‚
â”‚   FOLDS=2; REPEATS=3            â†’ 2Ã—3 = 6 OOF predictions (fast test)    â”‚
â”‚   (Tradeoff: more FOLDSÃ—REPEATS = longer training but more robust)       â”‚
â”‚                                                                            â”‚
â”‚ HYPERPARAMETER SEARCH BREADTH (Inner CV)                                â”‚
â”‚   INNER_FOLDS=5; N_ITER=200     â†’ thorough search (production)          â”‚
â”‚   INNER_FOLDS=2; N_ITER=3       â†’ minimal search (quick test)            â”‚
â”‚   (Tradeoff: more iterations = better hyperparams but much slower)       â”‚
â”‚                                                                            â”‚
â”‚ DIMENSIONALITY REDUCTION                                                â”‚
â”‚   SCREEN_TOP_N=1000; K_GRID=..  â†’ 2920 proteins â†’ ~100-800 features    â”‚
â”‚   STABILITY_THRESH=0.75         â†’ keep proteins selected in â‰¥75% folds  â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ WORKFLOW QUICK-START â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                             â”‚
â”‚ 1ï¸âƒ£ DEVELOPMENT (Quick iteration):                                         â”‚
â”‚    N_SPLITS=1 FOLDS=2 REPEATS=3 N_ITER=3 INNER_FOLDS=2 RUN_MODELS="LR" \ â”‚
â”‚      ./run.sh                                                             â”‚
â”‚    â†’ ~10 min for single model, LR only                                    â”‚
â”‚                                                                             â”‚
â”‚ 2ï¸âƒ£ QUALITY TESTING (All models, good CV):                               â”‚
â”‚    RUN_MODELS="RF,XGB,SVM,LR" FOLDS=5 REPEATS=10 N_ITER=200 \            â”‚
â”‚      INNER_FOLDS=5 N_SPLITS=1 SCORING="neg_brier_score" ./run.sh        â”‚
â”‚    â†’ ~6-8 hours total (training time, 4 models)                          â”‚
â”‚                                                                             â”‚
â”‚ 3ï¸âƒ£ ROBUST PUBLICATION READY (Repeated splits for CIs):                  â”‚
â”‚    N_SPLITS=10 RUN_MODELS="RF,XGB,SVM,LR" FOLDS=5 REPEATS=10 \          â”‚
â”‚      N_ITER=200 INNER_FOLDS=5 SCORING="neg_brier_score" ./run.sh       â”‚
â”‚    â†’ ~60-80 hours total (10 seeds Ã— 4 models)                            â”‚
â”‚                                                                             â”‚
â”‚ 4ï¸âƒ£ FINAL EXTERNAL VALIDATION (Holdout set):                             â”‚
â”‚    MODE=holdout RUN_MODELS="RF,XGB,SVM,LR" ./run.sh                     â”‚
â”‚    â†’ Creates separate holdout set (30%), runs training once              â”‚
â”‚    â†’ WARNING: Use ONLY for final reporting!                              â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ MODEL-SPECIFIC TUNING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                            â”‚
â”‚ LOGISTIC REGRESSION (LR_EN):                                             â”‚
â”‚   LR_C_MIN=1e-4 â†’ 1e-4 to 1e1 (20 log-spaced values)                   â”‚
â”‚   LR_L1_RATIO_GRID="0.01,0.05,...,0.60" â†’ mix of L1/L2                â”‚
â”‚   â†’ Best for: interpretable coefficients, probability calibration        â”‚
â”‚                                                                            â”‚
â”‚ RANDOM FOREST (RF):                                                      â”‚
â”‚   RF_MAX_DEPTH_GRID="8,10,12,14" (deeper = overfit risk)               â”‚
â”‚   RF_MIN_SAMPLES_LEAF_GRID="2,4,6" (higher = smoother)                â”‚
â”‚   RF_CPUS=8, RF_MEM=8000 (need high memory for permutation importance)  â”‚
â”‚   â†’ Best for: non-linear, feature importance, robust to outliers        â”‚
â”‚                                                                            â”‚
â”‚ XGBOOST:                                                                 â”‚
â”‚   XGB_MAX_DEPTH_GRID="3,7" (shallow for high-dim data)                â”‚
â”‚   XGB_LEARNING_RATE_GRID="0.01,0.1" (smaller = slower but better)     â”‚
â”‚   XGB_SCALE_POS_WEIGHT="auto" (auto = ~295 for Celiac imbalance)       â”‚
â”‚   â†’ Best for: predictive power, speed, nonlinear interactions            â”‚
â”‚                                                                            â”‚
â”‚ LINEAR SVM (LinSVM_cal):                                                 â”‚
â”‚   SVM_C_MIN=1e-4 â†’ 1e-4 to 1e4 (10 log-spaced values)                 â”‚
â”‚   CALIBRATION_METHOD="sigmoid" (fit sigmoid to map scoresâ†’probabilities)â”‚
â”‚   â†’ Best for: high-dimensional data, margin-based separation            â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ CLINICAL DECISION CONFIGURATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                            â”‚
â”‚ WHAT THRESHOLD TO USE?                                                   â”‚
â”‚   THRESHOLD_OBJECTIVE="fixed_spec"  â†’ target 95% specificity            â”‚
â”‚   FIXED_SPEC=0.95                   â†’ 95% = 5% false positive rate      â”‚
â”‚   THRESHOLD_SOURCE="val"            â†’ select on VAL (default, no leakage)â”‚
â”‚   TARGET_PREVALENCE_SOURCE="test"   â†’ use TEST prevalence for calibrationâ”‚
â”‚                                                                            â”‚
â”‚ WHAT METRICS TO REPORT?                                                 â”‚
â”‚   CONTROL_SPEC_TARGETS="0.95,0.99"  â†’ sensitivity at 95%, 99% specificityâ”‚
â”‚   TOPRISK_FRACS="0.01,0.05"         â†’ performance in top 1%, 5% risk   â”‚
â”‚   DCA_REPORT_POINTS="0.005,0.01,..."â†’ Decision curve at key prevalencesâ”‚
â”‚                                                                            â”‚
â”‚ CALIBRATION: How close are predictions to true risk?                    â”‚
â”‚   CALIBRATE_FINAL_MODELS=1          â†’ fit curve on VAL, apply to TEST  â”‚
â”‚   CALIB_BINS=6                      â†’ histogram bins for calibration   â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ PANEL BUILDING (Practical biomarker panels) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                            â”‚
â”‚ CONSTRUCT CLINICAL PANELS:                                              â”‚
â”‚   BUILD_PANELS=1                    â†’ 1=build panels, 0=skip             â”‚
â”‚   PANEL_SIZES="10,25,50,100,200"    â†’ sizes to create (10 vs 800 proteins)â”‚
â”‚   PANEL_CORR_THRESH=0.85            â†’ remove correlated proteins        â”‚
â”‚   PANEL_REFIT=1                     â†’ refit model on selected proteins  â”‚
â”‚   PANEL_STABILITY_MODE="rskf"       â†’ "rskf" (thorough) or "audit"     â”‚
â”‚                                                                            â”‚
â”‚ Why? Smaller panels (10-50 proteins) more practical for labs than 2920  â”‚
â”‚ Trade-off: smaller panel = easier to implement but slightly lower accuracyâ”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ RESOURCE MANAGEMENT (LSF Job Submission) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                            â”‚
â”‚ Per-model CPU & Memory Requirements:                                     â”‚
â”‚                                                                            â”‚
â”‚  RF:   8 CPUs Ã— 8GB/CPU = 64GB total    (Need high-mem nodes)          â”‚
â”‚  XGB:  8 CPUs Ã— 4GB/CPU = 32GB total    (Histogram method, moderate)   â”‚
â”‚  SVM:  8 CPUs Ã— 2GB/CPU = 16GB total    (Lightweight)                  â”‚
â”‚  LR:   8 CPUs Ã— 2GB/CPU = 16GB total    (Lightweight)                  â”‚
â”‚                                                                            â”‚
â”‚ Walltime Estimates:                                                      â”‚
â”‚  Single model: 2-6 hours (varies with FOLDS, REPEATS, N_ITER)          â”‚
â”‚  4 models (parallel): still 2-6 hours (submitted in parallel)           â”‚
â”‚  10 repeated splits: multiply by ~10 (same model, different seeds)      â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ MONITOR & DEBUG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                            â”‚
â”‚ Watch job status:                                                        â”‚
â”‚   bjobs -w | egrep "CeD_RF|CeD_XGB|CeD_SVM|CeD_LR|postproc|viz"        â”‚
â”‚                                                                            â”‚
â”‚ Tail live logs:                                                          â”‚
â”‚   tail -f logs_LR_1.17.26_a/*.live.log                                 â”‚
â”‚                                                                            â”‚
â”‚ Check completed models:                                                  â”‚
â”‚   ls -la results_LR_1.17.26_a/*/core/test_metrics.csv                  â”‚
â”‚                                                                            â”‚
â”‚ Run postprocessing after models complete:                               â”‚
â”‚   POSTPROCESS_NOW=1 ./run.sh                                            â”‚
â”‚   (or wait for automatic postprocess job to submit)                     â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

KEY FILES:
  ğŸ“„ run.sh                    â†’ Pipeline orchestration (LSF job submission)
  ğŸ“„ CeD_optimized.lsf         â†’ Model training configuration (4 model specs)
  ğŸ“„ CONFIGURATION_GUIDE.md    â†’ Full parameter reference
  ğŸ“„ KNOBS_CHEATSHEET.txt      â†’ This file (quick reference)

PRODUCTION DEFAULTS (what to set for final publication-ready results):
  SCORING="neg_brier_score"    (optimize calibration, not just discrimination)
  FOLDS=5 REPEATS=10           (50 OOF predictions per sample)
  INNER_FOLDS=5; N_ITER=200    (thorough hyperparameter search)
  N_SPLITS=10                  (10 repeated splits for robust CIs)
  RUN_MODELS="RF,XGB,SVM,LR"  (all 4 models for comparison)
