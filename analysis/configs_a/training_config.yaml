# Training Configuration
# Model training for Celiac Disease risk prediction

scenario: IncidentPlusPrevalent  # Options: IncidentOnly, PrevalentOnly, IncidentPlusPrevalent

# Cross-validation
cv:
  folds: 2
  repeats: 2
  scoring: roc_auc  # Options: roc_auc, average_precision, neg_brier_score
  # n_iter: 2  # Default RandomizedSearchCV iterations (can be overridden per-model below)
  inner_folds: 2
  n_jobs: -1  # Use all available CPUs
  random_state: 42
  grid_randomize: true  # Randomize numeric grid values for more diverse search
  verbose: 1

# Ensemble configuration (stacking multiple models)
# NOTE: Ensemble training is now a separate CLI command: `ced train-ensemble`
# This section defines default parameters for ensemble meta-learner only
ensemble:
  method: stacking  # Options: stacking, blending, weighted_avg (only stacking implemented)
  base_models: [LR_EN, RF, XGBoost, LinSVM_cal]  # Default models to combine
  meta_model:
    type: logistic_regression  # Meta-learner type
    penalty: l2  # Regularization: l2, l1, elasticnet, none
    C: 1.0  # Inverse regularization strength
    max_iter: 1000  # Max iterations for convergence
    solver: lbfgs  # Solver for logistic regression
  use_probabilities: true  # Use probabilities (true) or logits (false)
  passthrough: false  # Include original features in meta-learner (not yet implemented)
  cv_for_meta: 5  # CV folds for meta-model calibration

# Optuna hyperparameter optimization (optional alternative to RandomizedSearchCV)
optuna:
  enabled: true  # Set to true to use Optuna instead of RandomizedSearchCV
  n_trials: 3  # Number of hyperparameter trials
  timeout: null  # Optional timeout in seconds (null = no limit)
  sampler: tpe  # Options: tpe, random, cmaes, grid
  sampler_seed: 42  # Seed for reproducibility
  pruner: hyperband  # Options: median, percentile, hyperband, none
  pruner_n_startup_trials: 5  # Number of trials before pruning starts
  pruner_percentile: 25.0  # Percentile for percentile pruner (0-100)
  n_jobs: -1  # Number of parallel jobs for Optuna
  save_study: true  # Save Optuna study object
  save_trials_csv: true  # Save trials as CSV

# Feature selection
features:
  feature_select: hybrid  # "none", "kbest", "l1_stability", "hybrid"
  kbest_scope: protein
  kbest_max: 800
  k_grid: [25, 50, 100, 200, 300, 400, 600, 800]
  l1_c_min: 0.001  # For l1_stability method
  l1_c_max: 1.0
  l1_c_points: 4
  l1_stability_thresh: 0.70
  hybrid_kbest_first: true
  hybrid_k_for_stability: 200

  # Screening (pre-filter before k-best)
  screen_method: mannwhitney  # "mannwhitney" or "f_classif"
  screen_top_n: 1000  # 0 = no screening

  # Stability selection
  stability_thresh: 0.75  # Minimum frequency across folds

  # Correlation pruning
  stable_corr_thresh: 0.85  # Remove features with r > 0.85

# Model-specific hyperparameter search spaces
# These define the ranges for RandomizedSearchCV or Optuna optimization
#
# IMPORTANT: Parameters like max_iter and solver are FIXED (not tuned).
# They are set as baseline model parameters used by BOTH RandomizedSearchCV and Optuna.
# Only parameters with grids/ranges (C, l1_ratio, class_weight) are tuned.

# Logistic Regression (LR_EN, LR_L1)
lr:
  # Tuned parameters (explored by RandomizedSearchCV/Optuna):
  C_min: 0.0001             # Min regularization strength (log-spaced)
  C_max: 100.0              # Max regularization strength
  C_points: 7               # Number of C values in search grid
  l1_ratio: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] # ElasticNet mixing (0=L2, 1=L1) - tuned for LR_EN only
  class_weight_options: "balanced"  # Options: "None", "balanced", "{0:1,1:5}"

  # Optuna-specific ranges (optional, override C_min/C_max):
  # optuna_C: [1.0e-5, 100.0]                 # (min, max) for C (log-scale sampling)
  # optuna_l1_ratio: [0.0, 1.0]               # (min, max) for l1_ratio (continuous)

  # Fixed parameters (used as baseline for all trials):
  solver: saga              # Solver supporting L1/ElasticNet
  max_iter: 5000            # Max iterations for convergence (increase if seeing warnings)

  # Search algorithm settings:
  n_iter: 2                 # RandomizedSearchCV iterations (ignored if optuna.enabled=true)

# Linear SVM (LinSVM_cal) - wrapped in CalibratedClassifierCV
svm:
  # Tuned parameters (explored by RandomizedSearchCV/Optuna):
  C_min: 0.01               # Min regularization
  C_max: 10.0               # Max regularization
  C_points: 4               # Number of C values
  class_weight_options: "balanced"

  # Optuna-specific ranges (optional, override C_min/C_max):
  # optuna_C: [1.0e-3, 100.0]                 # (min, max) for C (log-scale sampling)

  # Fixed parameters (used as baseline for all trials):
  max_iter: 5000            # SVM convergence iterations (increase if seeing warnings)

  # Search algorithm settings:
  n_iter: 2                 # RandomizedSearchCV iterations (ignored if optuna.enabled=true)

# Random Forest (RF)
rf:
  # Tuned parameters (explored by RandomizedSearchCV/Optuna):
  n_estimators_grid: [100, 300, 500]          # Number of trees
  max_depth_grid: [null, 10, 20, 30]          # Tree depth (null = unlimited)
  min_samples_split_grid: [2, 5, 10]          # Min samples to split node
  min_samples_leaf_grid: [1, 2, 4]            # Min samples in leaf
  max_features_grid: ["sqrt", "log2", 0.5]    # Features per split
  class_weight_options: "balanced"

  # Optuna-specific ranges (optional, override grid-derived ranges)
  # Uncomment to enable wider continuous search with Optuna:
  # optuna_n_estimators: [50, 500]            # (min, max) for n_estimators
  # optuna_max_depth: [3, 20]                 # (min, max) for max_depth
  # optuna_min_samples_split: [2, 20]         # (min, max) for min_samples_split
  # optuna_min_samples_leaf: [1, 10]          # (min, max) for min_samples_leaf
  # optuna_max_features: [0.1, 1.0]           # (min, max) fraction for max_features

  # Search algorithm settings:
  n_iter: 2                 # RandomizedSearchCV iterations (ignored if optuna.enabled=true)

# XGBoost
xgboost:
  # Tuned parameters (explored by RandomizedSearchCV/Optuna):
  n_estimators_grid: [100, 300, 500]          # Boosting rounds
  max_depth_grid: [3, 5, 7, 10]               # Tree depth
  learning_rate_grid: [0.01, 0.05, 0.1, 0.3]  # Step size shrinkage
  subsample_grid: [0.7, 0.8, 1.0]             # Row subsampling
  colsample_bytree_grid: [0.7, 0.8, 1.0]      # Column subsampling
  scale_pos_weight_grid: [1.0, 2.0, 5.0]      # Class imbalance handling
  min_child_weight_grid: [1, 3, 5]            # Regularization: min child weight
  gamma_grid: [0.0, 0.1, 0.3]                 # Regularization: min split loss
  reg_alpha_grid: [0.0, 0.01, 0.1]            # L1 regularization
  reg_lambda_grid: [1.0, 2.0, 5.0]            # L2 regularization

  # Optuna-specific ranges (optional, override grid-derived ranges)
  # These enable wider continuous search with proper log-scale sampling.
  # Uncomment to customize ranges (defaults are used if not specified):
  # optuna_n_estimators: [50, 500]            # (min, max) for n_estimators
  # optuna_max_depth: [2, 12]                 # (min, max) for max_depth
  # optuna_learning_rate: [0.001, 0.3]        # (min, max) for learning_rate (log-scale)
  # optuna_min_child_weight: [0.1, 10.0]      # (min, max) for min_child_weight (log-scale)
  # optuna_gamma: [0.0, 1.0]                  # (min, max) for gamma
  # optuna_subsample: [0.5, 1.0]              # (min, max) for subsample
  # optuna_colsample_bytree: [0.5, 1.0]       # (min, max) for colsample_bytree
  # optuna_reg_alpha: [1.0e-8, 1.0]           # (min, max) for reg_alpha (log-scale)
  # optuna_reg_lambda: [1.0e-8, 10.0]         # (min, max) for reg_lambda (log-scale)

  # Fixed parameters (used as baseline for all trials):
  tree_method: hist                            # Algorithm: hist (fast), exact, approx

  # Search algorithm settings:
  n_iter: 2                 # RandomizedSearchCV iterations (ignored if optuna.enabled=true)

# Probability calibration
# Controls how model probabilities are calibrated for better reliability
calibration:
  enabled: true  # Whether to apply any calibration
  strategy: per_fold  # Options: per_fold (default), oof_posthoc, none
  # - per_fold: Apply CalibratedClassifierCV inside each CV fold (current behavior, simple)
  # - oof_posthoc: Fit calibrator on pooled OOF predictions after CV (eliminates ~0.5-1% bias)
  # - none: No calibration applied
  method: isotonic  # Options: isotonic (nonparametric), sigmoid (Platt scaling)
  cv: 5  # CV folds for per_fold strategy
  # Per-model overrides (optional):
  # per_model:
  #   LR_EN: oof_posthoc  # Use oof_posthoc for logistic regression
  #   RF: per_fold        # Keep per_fold for random forest
  #   XGBoost: none       # No calibration for XGBoost

# Thresholding
thresholds:
  objective: fixed_spec  # "max_f1", "max_fbeta", "youden", "fixed_spec", "fixed_ppv"
  fixed_spec: 0.95  # Target 95% specificity
  fbeta: 1.0  # Beta parameter for max_fbeta objective
  fixed_ppv: 0.10  # Target PPV for fixed_ppv objective
  threshold_source: val  # Select threshold on VAL set
  target_prevalence_source: test  # Use TEST prevalence for calibration
  target_prevalence_fixed: null  # Override prevalence for calibration
  risk_prob_source: test  # Options: test, val

# Evaluation
evaluation:
  test_ci_bootstrap: true
  n_boot: 500
  boot_random_state: 0
  learning_curve: true
  lc_train_sizes: [0.1, 0.25, 0.5, 0.75, 1.0]
  feature_reports: true
  feature_report_max: 200
  # Specificity targets for multi-target reporting
  # Computes sensitivity/precision at each target specificity
  # Output keys: sens_ctrl_90, prec_ctrl_90, thr_ctrl_90, etc.
  # Useful for clinical decision-making across risk tolerance levels
  control_spec_targets: [0.90, 0.95, 0.99]
  toprisk_fracs: [0.01, 0.05, 0.10]

# Decision curve analysis
dca:
  compute_dca: true
  dca_threshold_min: 0.0005
  dca_threshold_max: 1.0
  dca_threshold_step: 0.001
  dca_report_points: [0.01, 0.05, 0.10, 0.20]

# Outputs
output:
  save_train_preds: true
  save_train_oof: true
  save_val_preds: true
  save_test_preds: true
  save_calibration: true
  calib_bins: 6
  save_controls_oof: true
  save_feature_importance: true
  feature_reports: true
  plot_format: png  # Options: png, pdf, svg
  plot_dpi: 300
  save_plots: true

  # Individual plot type controls
  plot_roc: true
  plot_pr: true
  plot_calibration: true
  plot_risk_distribution: true
  plot_dca: true
  plot_learning_curve: true
  plot_oof_combined: true
  plot_optuna: true
